# 灾难救援调度系统

## 一、项目概述
本项目围绕灾难救援调度问题展开，提供了多种算法和策略来优化救援资源的分配，以最大程度地减少受灾人员伤亡。项目中包含了不同的救援任务分配策略、元启发式算法、多智能体策略优化（MAPPO）等多种方法。同时，项目还提供了一个基于 React 的可视化界面，方便用户进行模拟和调试。
多智能体策略通过参数优化可以显著提升救援效率。本系统引入了分区城市地图，各区域具有不同紧急程度特征（南区和西区以高紧急度任务为主，东区以低紧急度任务为主）。多智能体策略的优势在于能够根据任务的紧急程度、位置和人数进行动态决策，并将救援团队分配到不同区域，避免救援资源在单一区域集中。当地图上任务点高度分散时，多智能体策略比单一策略的效率可提升 40-60%，展现出真正的协同救援优势。

## 二、项目结构
```bash
├── public/
│   └── assets/
│       ├── nearest.png
│       ├── largest.png
│       └── multiagnet.png
├── src/
│   ├── distribute_strategy.py
│   ├── Metaheuristics.py
│   ├── genetic_programming.py
│   ├── mappo.py
│   └── App.js
├── package.json
├── package-lock.json
├── README.md
```

## 三、图例说明

在可视化界面中，地图上的不同颜色和救援队伍的数字标识代表着不同的含义：

### 地图区域
| 颜色 | 说明 |
| :--- | :--- |
| ![Red Square](https://placehold.co/15x15/E04C4C/E04C4C.png) | **高紧急度**：该区域的任务通常具有较高的优先级和紧急性。 |
| ![Orange Square](https://placehold.co/15x15/FF9C29/FF9C29.png) | **中紧急度**：该区域的任务紧急程度适中。 |
| ![Blue Square](https://placehold.co/15x15/4C7BE0/4C7BE0.png) | **中紧急度**：该区域的任务紧急程度适中。 |
| ![Green Square](https://placehold.co/15x15/6CC24A/6CC24A.png) | **低紧急度**：该区域的任务紧急程度相对较低。 |

### 救援队伍
| 标识 | 说明 |
| :--- | :--- |
| ![Team 5 Blue](https://placehold.co/20x20/4C7BE0/FFFFFF?text=5) | **最近优先队伍**：采用“最近优先”策略进行任务分配的救援队伍。 |
| ![Team 5 Red](https://placehold.co/20x20/E04C4C/FFFFFF?text=5) | **最大优先队伍**：采用“最大优先”策略进行任务分配的救援队伍。 |
| ![Team 3 Green](https://placehold.co/20x20/6CC24A/FFFFFF?text=3) | **多智能体 - 最近优先**：多智能体策略中，倾向于“最近优先”分配任务的救援队伍。 |
| ![Team 2 Purple](https://placehold.co/20x20/9B59B6/FFFFFF?text=2) | **多智能体 - 最大优先**：多智能体策略中，倾向于“最大优先”分配任务的救援队伍。 |
| ![Team 4 Orange](https://placehold.co/20x20/FF9C29/FFFFFF?text=4) | **多智能体 - 混合策略**：多智能体策略中，采用混合分配策略的救援队伍。 |

---

## 四、主要模块介绍

本项目旨在通过不同的调度策略和优化算法，解决城市灾难救援中的任务分配问题。各个模块在功能上相互联系，逐步从基础策略到高级智能优化。
### 1. `distribute_strategy.py`
- **功能**：此模块构成了整个救援模拟系统的基础框架。它不仅实现了**两种核心的基础任务分配策略**（最近任务优先和最大受灾人数优先），还包含了**多智能体模拟环境**的核心逻辑，并利用**蒙特卡洛算法**进行救援小组的配置和策略分配。这是后续所有高级优化算法进行仿真和评估的基石。
- **核心类与策略**：
  - `Task`：定义了救援任务的基本属性，如位置、受灾人数、衰减率和报告时间。
  - `Rescuer`：定义了单个救援人员的状态和行为。
  - `Simulation`：所有模拟环境的基类，负责初始化灾情场景（包括灾情点生成、救援中心设置），并提供距离计算等通用功能。
  - `NearestFirstSimulation`（最近任务优先）：
    - **策略描述**：救援人员每次任务分配时，优先选择距离其当前位置最近的灾情点。
    - **适用场景**：适用于灾情分布密集、数量多且位置接近的场景，旨在最大化救援频率和响应速度。
  - `LargestFirstSimulation`（最大受灾人数优先）：
    - **策略描述**：救援人员优先选择受灾人数最多、受灾程度最严重的灾情点。
    - **适用场景**：适用于局部区域发生重大灾害或重灾区明显的情形，旨在最大程度降低灾害损失。
  - `MultiAgentSimulation`（多智能体模拟环境）：
    - **混合策略 (`HYBRID`)**：在此基础多智能体模拟中，混合策略根据受灾人数与距离的综合评分进行任务选择。
    - **蒙特卡洛算法 (`allocate_rescuers` 函数)**：通过随机抽样和三角分布，动态生成救援小组的数量、人数分配和能力值（总和固定）。同时，为每个小组随机分配初始的救援策略类型（`NEAREST`、`LARGEST`、`HYBRID`）。这个机制使得系统能够在大规模的随机配置中评估不同分组和策略组合的效果，为后续的优化算法提供多样化的训练数据。
- **与后续模块的关联**：`distribute_strategy.py` 提供的 `Simulation` 基础类和 `MultiAgentSimulation` 环境，为 `Metaheuristics.py` 和 `genetic_programming.py` 的算法提供了模拟和评估任务分配策略的平台。它定义了任务和救援人员的基本交互逻辑，而其他模块则在此基础上优化决策过程。
### 2. `Metaheuristics.py`
- **功能**：在此模块中，我们采用**元启发式调度**方法，并结合**遗传算法**来优化**固定形式的**救援小组任务评分函数。与 `distribute_strategy.py` 中预设的简单策略不同，此模块旨在通过学习找到每个救援小组最佳的任务决策权重。更重要的是，它能够学习并拟合救援小组的能力（`ability`）与任务评分权重（`w1, w2`）之间的线性映射关系，实现系统级的自适应调度。
- **核心类与策略**：
  - `Task` 和 `RescueGroup`：沿用了 `distribute_strategy.py` 中的定义，但 `RescueGroup` 额外包含了 `w1` 和 `w2` 权重属性，用于其评分函数。
  - **任务分配评分函数 (自学习)**：每个救援小组根据自身能力和通过遗传算法优化得到的 `w1, w2` 权重来计算任务的得分。评分函数表达为：`score = w1 * distance + w2 * expected_victims`。
  - **遗传算法训练 (`train()` 函数)**：
    - **目标**：优化所有救援小组的 `w1, w2` 权重组合，以最大化综合适应度（Fitness）。
    - **适应度评估 (`evaluate()` 函数)**：综合考虑救援总人数、首次到达时间与上报时间之差、超时未完成任务数和各组任务分配的标准差。
    - **训练流程**：通过多代迭代，进行种群选择（精英保留）、交叉（交换优秀基因）和变异（引入随机探索），逐步收敛到最优权重组合。
  - **任务抢占机制**：救援小组若发现新任务评分更优，允许更换当前目标，但设置 `delay` 参数以避免频繁切换造成的效率损失。
  - **能力与评分权重的映射学习 (`fit_ability_to_weight()` 函数)**：这是此模块的关键创新点。在多次遗传算法训练（针对不同规模的灾情）后，系统会记录每个救援小组的能力值与对应训练出的最优 `w1, w2` 权重。随后，使用`LinearRegression`（或 `Ridge` 回归）拟合能力与 `w1` 和 `w2` 之间的线性关系（例如：`w1 = a * ability + b`）。这使得系统在面对新的救援场景时，无需重新训练，即可根据小组能力自动推断出合适的任务评分权重，显著提高了自适应能力和泛化性。
- **与前后模块的关联**：`Metaheuristics.py` 在 `distribute_strategy.py` 提供的模拟环境上运行，通过遗传算法优化小组的决策逻辑。其学习到的能力-权重映射关系，可以为其他高级策略（如 `App.js` 中的网格搜索或 `mappo.py` 的初始化）提供经验性指导，帮助它们更快地收敛到有效的调度方案。
### 3. `genetic_programming.py`
- **功能**：此模块采用**遗传编程（Genetic Programming, GP）**算法来**自动生成和优化**救援任务的评分函数。与 `Metaheuristics.py` 中优化固定形式（例如线性加权）的评分函数不同，GP 能够探索和构建**任意复杂的表达式树**，从而发现非预设的、更具适应性的任务评估逻辑。这赋予了调度策略更大的灵活性和对未知情境的鲁棒性。
- **核心类与策略**：
  - `Task` 和 `RescueGroup`：沿用了基础定义，但 `RescueGroup` 的 `score_expr` 属性用于存储评分函数表达式树。
  - `ExprNode` 及其子类 (`ConstNode`, `VarNode`, `BinaryOpNode`, `UnaryOpNode`)：这些类是构建评分函数表达式树的基本单元。
    - `ConstNode`：常量，例如权重或阈值。
    - `VarNode`：变量，代表任务的属性，如距离（`d`）、预计受灾人数（`v`）、救援小组能力（`a`）等。
    - `BinaryOpNode`：二元操作符，如 `+`, `-`, `*`, `/`, `^`。
    - `UnaryOpNode`：一元操作符，如 `log`, `exp`, `sin`, `cos`, `abs`, `sqrt`。
  - **随机表达式生成 (`generate_random_expr` 和 `generate_base_expr`)**：在初始种群中，随机生成不同深度和复杂度的表达式树，其中 `generate_base_expr` 提供了一种基础的线性组合作为出发点。
  - **遗传操作**：
    - **变异 (`mutate`)**：随机改变表达式树的局部结构，如替换节点、改变操作符，引入多样性。
    - **交叉 (`crossover`)**：交换两个父代表达式树的子树，融合它们的优秀特征，产生新的评分函数。
  - **适应度评估**：与 `Metaheuristics.py` 类似，通过模拟救援过程，评估生成的评分函数在救援总人数、响应时间、逾期任务数和资源分配公平度等方面的表现。为了防止过度复杂化，评估中还加入了对表达式树深度的**正则化项**。
- **与前后模块的关联**：`genetic_programming.py` 提供了一种强大的自动化设计策略方法，可以与 `Metaheuristics.py` 的参数优化形成互补。它能发现连人类都可能想不到的有效评分公式，并将这些“发现”用于指导实际调度或作为 `mappo.py` 等强化学习模型的特征工程。
### 4. `mappo.py`
- **功能**：实现了**多智能体近端策略优化**算法，这是一种基于强化学习的高级调度策略。它通过让救援队伍作为独立但协作的智能体，在模拟环境中自主学习最优的救援任务分配策略，从而应对动态变化的灾情环境，实现全局最优的救援效果。
- **核心类与算法**：
  - `Task` 和 `RescueGroup`：沿用了基础定义。
  - `EmergencyEnv`：强化学习环境的抽象，包含了任务、救援小组和时间进程。它负责处理智能体的动作、更新环境状态、并计算奖励信号。
    - **观察空间**：包括救援小组自身的位置、能力、状态，以及所有任务的位置、剩余人数、衰减率、是否被分配等信息，这些信息被归一化处理。
    - **动作空间**：每个智能体可以选择分配给某个特定任务，或者选择“不选择任务”动作。
    - **奖励机制**：设计了综合奖励，包括单个救援小组选择任务的优先级奖励（考虑任务剩余人数、小组能力、距离），以及全局奖励（如救援人数增量奖励、总救援比例奖励），同时施加时间惩罚和重复选择任务的惩罚。
  - `Actor` (策略网络)：基于神经网络，接收环境观察，输出每个智能体选择动作的概率分布。采用 LayerNorm 和 Orthogonal 初始化来提高训练稳定性。
  - `Critic` (价值网络)：基于神经网络，接收环境观察，评估当前状态的价值，用于指导策略更新。同样采用 LayerNorm 和 Orthogonal 初始化。
  - `MAPPO` (算法核心)：实现了 MAPPO 算法的详细逻辑。
    - **动作选择**：智能体根据 Actor 网络输出的概率分布进行采样，选择执行的动作。
    - **优势估计 (GAE)**：利用广义优势估计来更准确地评估动作的价值，以指导策略更新。
    - **策略更新 (PPO)**：使用 PPO（Proximal Policy Optimization）算法的裁剪目标函数来更新 Actor 网络，确保策略更新的稳定性和效率。
    - **价值更新**：使用 MSE 损失函数更新 Critic 网络。
    - **梯度裁剪**：防止梯度爆炸。
- **与前后模块的关联**：`mappo.py` 代表了本项目的最先进调度算法。它可以通过强化学习的方式，从零开始学习复杂的协作策略，而无需预设评分函数形式或手动调整权重。其训练好的模型可以直接应用于 `App.js` 进行可视化演示，展示其在动态环境下的决策能力。
### 5. `App.js`
- **功能**：作为整个系统的**可视化界面和用户交互中心**，`App.js` 提供了一个基于 React 的丰富界面，它允许用户直观地观察、控制和分析灾难救援模拟。其核心亮点在于能够**实时在网页端进行策略训练和比较**。
- **核心功能亮点**：
  - **地图随机生成与可视化**：每次模拟开始时，系统能够**随机生成**具有不同灾情分布的城市地图，确保模拟的多样性和真实性。所有的灾情点、救援队伍的实时位置和移动轨迹都会在地图上**动态可视化展示**，让用户清晰掌握救援进展。
  - **实时网页端训练 (基于网格搜索的混合策略)**：
    - 用户可以在网页界面上直接启动**基于网格搜索的策略训练**。
    - 系统会自动遍历预定义的多种参数组合（包括队伍数量、队伍人数分配方式、调度策略比例、混合策略的评分权重），在多个随机生成的训练场景中运行模拟。
    - **参数展示**：训练过程中，界面会清晰地**展示当前正在评估的参数组合**。
    - **实时反馈**：用户可以实时查看训练进度、当前最佳策略的性能指标（如救援成功率、完成时间），并观察策略在不同场景下的表现。
    - **自动寻优**：训练结束后，系统将自动识别并保存最优的策略参数组合，解决传统手动调参的主观性和局限性。
  - **多种策略实时比较**：
    - 界面支持同时运行并展示**多种不同策略**（例如最近任务优先、最大任务优先、多智能体策略）的救援效果。
    - 通过并排的模拟画面和**实时图表**（如救援成功率、完成时间、高紧急度任务响应率），用户可以直观地**比较**不同策略在同一灾情场景下的性能差异，辅助决策和策略优化。
  - **直观的交互体验**：用户可以通过按钮（开始、暂停、重置、训练）轻松控制模拟进程，并调整各项模拟参数，极大地提升了系统的易用性和可调试性。

## 五、演示图片

以下是不同救援策略在模拟中的效果演示：

### 1. 最近优先 (Nearest First) 策略

![最近优先策略演示](public/assets/nearest.png)
*说明：此图展示了采用“最近优先”策略时的救援队伍分配情况。救援队伍会优先选择距离最近的任务进行救援。*

### 2. 最大优先 (Largest First) 策略

![最大优先策略演示](public/assets/largest.png)
*说明：此图展示了采用“最大受灾人数优先”策略时的救援队伍分配情况。救援队伍会优先选择受灾人数最多的任务进行救援。*

### 3. 多智能体 (Multi-Agent) 策略

![多智能体策略演示](public/assets/multiagent.png)
*说明：此图展示了采用多智能体策略时的救援队伍分配情况。该策略结合了任务的紧急程度、位置和人数进行动态决策，以达到全局最优。*

## 六、使用方法

### 1. 安装依赖
本项目使用了 `torch`、`numpy`、`matplotlib`、`sklearn`、`react`、`lucide-react` 等库，请确保这些库已经安装。可以使用以下命令进行安装：
```bash
# 安装 Python 依赖
pip install torch numpy matplotlib scikit-learn

# 安装 Node.js / React 依赖
npm install
```

### 2. 运行代码

#### 前端可视化界面
在项目根目录下，运行以下命令启动前端开发服务器：
```bash
npm start
```
打开浏览器，访问 `http://localhost:3000`，即可看到可视化界面。在界面中，你可以选择不同的场景、参数和策略，观察救援过程和结果。

#### Python 算法代码
你也可以直接运行 Python 代码来测试不同的算法和策略。例如，运行 `Metaheuristics.py` 进行元启发式调度训练：
```bash
python src/Metaheuristics.py
```

## 七、注意事项
- 本项目中的代码可以根据实际需求进行扩展和修改，例如调整算法参数、增加新的救援策略等。
- 在运行代码时，请确保输入的参数合理，避免出现异常情况。
- 部分代码中使用了随机数生成，可能会导致每次运行结果略有不同。如果需要可重复的结果，可以设置随机数种子。
